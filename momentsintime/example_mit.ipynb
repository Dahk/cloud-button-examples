{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import builtins\n",
    "from torch import save, load\n",
    "import torch.optim\n",
    "import torch.nn.parallel\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from models import load_model, load_transform, load_categories\n",
    "from utils import extract_frames, CloudFileProxy\n",
    "\n",
    "from cloudbutton import Pool, CloudStorage\n",
    "from cloudbutton.util import get_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_URL = 'http://moments.csail.mit.edu/moments_models'\n",
    "WEIGHTS_FILE = 'moments_RGB_resnet50_imagenetpretrained.pth.tar'\n",
    "\n",
    "# Download pretrained resnet50 model/weights\n",
    "if not os.access(WEIGHTS_FILE, os.R_OK):\n",
    "    os.system('wget ' + '/'.join([ROOT_URL, WEIGHTS_FILE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_EXEC = False\n",
    "INPUT_DATA_DIR = 'momentsintime/input_data'\n",
    "CONCURRENCY = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOCAL_EXEC:\n",
    "    initargs = {}\n",
    "    weights_location = '/dev/shm/' + WEIGHTS_FILE\n",
    "    video_locations = [os.path.abspath(os.path.join(INPUT_DATA_DIR, name)) \n",
    "                        for name in os.listdir(INPUT_DATA_DIR)]\n",
    "    open = builtins.open\n",
    "else:\n",
    "    RUNTIME = 'dhak/pywren-runtime-pytorch:3.6'\n",
    "    initargs = {\n",
    "        'runtime': RUNTIME,\n",
    "        'runtime_memory': 1024\n",
    "        }\n",
    "    weights_location = 'momentsintime/models/' + WEIGHTS_FILE\n",
    "    cloud_storage = CloudStorage()\n",
    "    #cloud_storage.put_data(key='momentsintime/input_data/juggling.mp4', data=open('momentsintime/input_data/juggling.mp4', 'rb'))\n",
    "    video_locations = cloud_storage.list_tmp_data(prefix=INPUT_DATA_DIR)\n",
    "    open = CloudFileProxy(cloud_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with builtins.open(WEIGHTS_FILE, 'rb') as f_in:\n",
    "    with open(weights_location, 'wb') as f_out:\n",
    "        f_out.write(f_in.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SEGMENTS = 16\n",
    "\n",
    "# Get dataset categories\n",
    "categories = load_categories()\n",
    "\n",
    "# Load the video frame transform\n",
    "transform = load_transform()\n",
    "\n",
    "def predict_video(open, weights_location, video_locations):\n",
    "    with open(weights_location, 'rb') as f:\n",
    "        model = load_model(f)\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())\n",
    "\n",
    "    for video_loc in video_locations:\n",
    "        start = time.time()\n",
    "        with open(video_loc, 'rb') as f_in:\n",
    "            with builtins.open(local_video_loc, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "        # Obtain video frames\n",
    "        frames = extract_frames(local_video_loc, NUM_SEGMENTS)\n",
    "\n",
    "        # Prepare input tensor [num_frames, 3, 224, 224]\n",
    "        input_v = torch.stack([transform(frame) for frame in frames])\n",
    "\n",
    "        # Make video prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_v)\n",
    "            h_x = F.softmax(logits, 1).mean(dim=0)\n",
    "            probs, idx = h_x.sort(0, True)\n",
    "\n",
    "        # Output the prediction\n",
    "        output = dict(key=video_loc, result={})\n",
    "        for i in range(0, 5):\n",
    "            output['predictions'][categories[idx[i]]] = round(float(probs[i]), 5)\n",
    "        output['whole_duration'] = time.time() - start\n",
    "        results.append(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyWren v1.5.2 init for IBM Cloud Functions - Namespace: pol23btr%40gmail.com_dev - Region: eu_gb\nExecutorID 043bf6/1 | JobID M000 - Selected Runtime: dhak/pywren-runtime-pytorch:3.6 - 1024MB \nExecutorID 043bf6/1 | JobID M000 - Uploading function and data - Total: 168.1KiB\n0/|/ 0/1ExecutorID 043bf6/1 | JobID M000 - Starting function invocation: predict_video()  - Total: 1 activations\nExecutorID 043bf6/1 - Getting results...\n1/|/ 1/1[{'key': 'momentsintime/input_data/juggling.mp4', 'result': {'juggling': 0.99872, 'flipping': 0.00027, 'catching': 0.00016, 'child+speaking': 6e-05, 'child+singing': 5e-05}, 'whole_duration': 1.9780809879302979}]\nExecutorID 043bf6/1 - Cleaning temporary data\n\n"
    }
   ],
   "source": [
    "with Pool(initargs=initargs) as pool:\n",
    "    iterable = [(open, weights_location, video_locations[n::CONCURRENCY]) \n",
    "                for n in range(CONCURRENCY) if n < len(video_locations)]\n",
    "    res = pool.map_async(func=predict_video, iterable=iterable)\n",
    "    print(res.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_video(open, weights_location, video_locations):\n",
    "    with builtins.open(weights_location, 'rb') as f:\n",
    "        model = load_model(f)\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "    local_video_loc = 'video_to_predict_{}.mp4'.format(get_uuid())\n",
    "\n",
    "    for video_loc in video_locations:\n",
    "        start = time.time()\n",
    "        with open(video_loc, 'rb') as f_in:\n",
    "            with builtins.open(local_video_loc, 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "        # Obtain video frames\n",
    "        frames = extract_frames(local_video_loc, NUM_SEGMENTS)\n",
    "\n",
    "        # Prepare input tensor [num_frames, 3, 224, 224]\n",
    "        input_v = torch.stack([transform(frame) for frame in frames])\n",
    "\n",
    "        # Make video prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_v)\n",
    "            h_x = F.softmax(logits, 1).mean(dim=0)\n",
    "            probs, idx = h_x.sort(0, True)\n",
    "\n",
    "        # Output the prediction\n",
    "        output = dict(key=video_loc, result={})\n",
    "        for i in range(0, 5):\n",
    "            output['predictions'][categories[idx[i]]] = round(float(probs[i]), 5)\n",
    "        output['whole_duration'] = time.time() - start\n",
    "        results.append(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_RUNTIME = 'dhak/pywren-runtime-resnet'\n",
    "weights_location = '/momentsintime/model_weights'\n",
    "\n",
    "initargs = {\n",
    "    'runtime': CUSTOM_RUNTIME, \n",
    "    'runtime_memory': 1024\n",
    "    }\n",
    "with Pool(initargs=initargs) as pool:\n",
    "    iterable = [(open, weights_location, video_locations[n::CONCURRENCY]) \n",
    "                for n in range(CONCURRENCY) if n < len(video_locations)]\n",
    "    res = pool.map_async(func=predict_video, iterable=iterable)\n",
    "    print(res.get())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "if os.path.isfile(WEIGHTS_FILE):\n",
    "    os.remove(WEIGHTS_FILE)\n",
    "\n",
    "if LOCAL_EXEC:\n",
    "    if os.path.isfile(weights_location):\n",
    "        os.remove(weights_location)\n",
    "else:\n",
    "    cloud_storage.delete_cobject(key=weights_location)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bit325e2e176c1e4c56af6d2bec6f3f9965",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}